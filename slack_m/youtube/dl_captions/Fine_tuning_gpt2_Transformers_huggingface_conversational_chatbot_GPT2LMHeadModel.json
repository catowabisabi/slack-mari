{
  "title": "Fine tuning gpt2 | Transformers huggingface | conversational chatbot | GPT2LMHeadModel",
  "summary": "詳細信息摘要：\n本文解釋瞭如何使用擁抱面孔庫在對話式AI數據集上微調GPT2模型。數據集由包含聊天的字典列表及其各自的答复。python代碼寫在main.pi文件中以使用該模型，而chatdata類則從torch.utils.data.dataset類中延長，以微調模型。令牌儀用於將字符串轉換為令牌，並且注意力面罩和輸入ID作為元組返回。然後，通過定義時期，以批處理形式獲取數據，設置優化器並將梯度設置為0來訓練該模型。在每個時期和定義一個函數以進行推理之後，也可以保存模型。最後，模型和數據設置為CUDA設備，並將數據的前3,000個樣本用於培訓。\n\n子彈點摘要：\n•說明如何在對話式AI數據集中微調GPT2模型\n•使用擁抱面孔變壓器庫和令牌將字符串轉換為令牌\n•數據集由包含聊天及其各自答复的字典列表組成\n•python代碼寫在main.pi文件中，chatdata類從torch.utils.data.dataset類延長\n•通過定義時期，以批處理形式獲取數據，設置優化器並將梯度設置為0來訓練模型\n•在每個時期和定義一個函數以進行推理之後，也可以保存模型\n•模型和數據設置為CUDA設備，並將數據的前3,000個樣本用於培訓",
  "dialogue": "hi everyone how is it going and in this, video we are going to fine tune gpt2, model we are basically going to train it, on conversational AI data set so in at, the end of this video you would be, having a chat bot type of gpt2 model so, basically we are going to use hugging, face Transformers Library uh in that we, have this jpt2 LM head model we are, going to fine tune this model over here, and the data set we are going to use, will be this data set basically so the, link to this data set will be in down, description so you can just come in over, here and click uh click on raw and once, this new page open you can just click on, anywhere in the blank space just save, the page and make sure you save the page, as Json and the main idea is at the end, of all of this you should have this chat, data.json file over here as you can see, it is basically a list of dictionaries, and in every dictionary we have the, chats like as you can see over here I, love iPhone I just bought new iPhone and, the reply to that is that's good for you, I'm not very into new tech and you just, get the main idea this is a, conversational data set we need to, filter out this data set so that we only, have this text pumped now in order to, use this Transformers you have to, install a Transformer so you just have, to save it install, Transformers and once you run this, Transformers once you run this it is, going to install the Transformers in, your computer and also you have to, install pytorch so just go on a run pip, install to run the install the pie torch, also, so let's start our main video over here, so first of all uh we are going to do, the basic stuff with the gpd2 LM head, model and then after that we will see, how we can fine tune it so I'm just, going to write a main dot pi and in this, we are going to write our main code, basically, so for using that gpd2lm head model you, just have to from, Transformers import, gpt2lm head model and also we are going, to use tokenizer for sure for uh, converting the length of string into, tokens basically integers so now in, order to use the pre-trained W2 LM head, model and tokenizer but you have to do, you have to say tokenizer is equal to, GPT to tokenizer Dot from pre-trained, and you have to pass as a string as this, GPT to and similarly we are going to use, this model so we'll say model is equals, to GPT to LM model and same this uh gpt2, now in order to use this model as it is, what you have to do uh you have to say, model dot generate and now this generate, function is going to take uh basically, the tokens so for that you have to pass, the string from the token we will say, hey, I was good at, basketball but, and now it is just going to generate the, text for us, um we can't pass it as it is we need to, convert it into the torch tensor so, we'll save return, tensors is equals to PD once you do this, we are going to print it, on the screen and as well as this is, going to return the dictionary so we, have to unpack the dictionary so we will, now try to run this in order to run this, you have to say Python main.pi and make, sure your terminal is pointing to the, same directory where this mean dot Pi is, so we'll just wait and see what do we, get so you see over here it is just, returning the token so we need to use, the token to decode this so one more, time we'll say tokenizer dot d code and, we need to access the zeroth from over, here since it's a 2d tensor let's run, this one more time and see what we get, forgot to save the file running one more, time, so as you can see over here it is, generating hey I was good at basketball, but uh from after this but it has, generated this I have never played, basketball before so I don't know how to, play so basically uh currently it is, about generating the prompts, now we need to fine tune this particular, gpt2 model on to this data set over here, now first what you have to do in order, to uh, fine tune this model you have to have a, data set class it is not necessary but, you are going to see that the things you, are going to get much manageable when we, create a data set class so let's do that, and you will get understanding why we, need to do that so I'm just going to, create a, chat data dot py now in this we are, going to Define our class for chat data, chat data class now it is going to uh, extend from, or inherit from the data set for now I'm, just going to say pass so we need to, import it so now in order to import we, are going to say from torch.eutils dot, um it's I guess data input, data set yes it is now uh in this data, set you have to uh basically Define some, functions since this is a abstract class, now in this you have to Define first of, all init and of course it is going to, take the self and for now let's just, pass pass and other you have to pass is, uh, I'm just going to open the documentation, because I don't remember it so I'll say, torch.utils dot data Dot dataset, yes you have to basically underscore, underscore length and get item so length, from self, and get item, and idx so basically inside this init we, are going to initialize all the, variables data stuff and everything and, inside this length what we are going to, return is the length of our data set and, inside this get item we are going to, return the particular item situated at, that particular index so it's just that, thing now over here we are going to get, the path which will be of kind of string, now once we have the path which is this, chat data.json file path we are going to, read the Json from there so I'm just, going to say self dot data is equals to, um I need to import Json also so, Json and I'll say Json dot loads and uh, I have to open this file from this path, as a read mode, and once you run this basically you are, going to get a list of this data, now we are going to iterate inside this, data we are going to get the dictionary, right so I'll say for I in self dot data, as you can see if we iterate we are, going to get the dictionary and from, this dictionary I want to access this, dialog and again in this dialog it is a, list so I'm going to say for J in since, I is a dictionary I am going to Target, this dialog, and inside this uh, J so now J will be a list of this, dictionary once again but from this, dictionary for every instance of J I, want to access this text so this text I, am going to append into a list I'm going, to say x and I'm going to say self.x dot, append, G text, to solve now one more thing I'm going to, take from this is tokenizer so in order, to convert the strings as you have, already seen in order to make the, prediction we need to convert this, string into the token by using the, tokenizer that's for sure after that uh, once we have the tokenizer once we have, all the prompts in our self.x I'm just, going to pass it from the tokenizer so, I'll just say cell dot X encoded, brokenizer and I'm just going to pass, this, self dot X and now in this I need to, pad this basically so I'll just make, this trunk question, equal to 2, other than that I'll make the padding, also equal to true, I guess that's enough, um okay so I guess this is enough one, more thing I would like to show you over, here uh let me just make it first of all, so I'll just import from Transformers, import, from, now if you see that if I pass basically, the string, from this tokenizer I'm going to get a, dictionary of input IDs and attention, mask so I'm just going to get the input, IDs self Dot, input IDs is equals to self dot X, encoded, input IDs and similarly I am just going, to get the attention mask also I'll say, attention, mask, attention mask now what I want to do is, uh basically as you can see, currently I'm going to have this thing, over here right what I want to do is, first of all have the, start of string token, over here and end of string, token over here in order to, tell our chatbot that this is the start, of string and this is the end of string, just like that, now after that I'm going to have a bot, reply for this so basically this will be, my prompt but I'm going to provide to, the uh chatbot and uh is in in reply but, I am expecting from the model is the, reply which will be the just next to it, which is uh this basically just like, that, so I need to take this string, and I need to pre-process that, everything and just append uh as these, tokens and this prompt or reply from the, chatbot so how can we do that uh, basically I'm once this all is appended, I'll just say for I in self dot X for I, and idx in self dot X I'm just going to, enumerate, basically now what I'm going to say is, self taught, X at that idx will be equal to start, start off string, plus I Plus, um, bought reply to this, and then uh the next one so I'll say, self dot x i plus 1 and after that the, end of string so I just see, end of string, just like that now uh this is going to, produce error for the last sample since, there will be no I plus 1 so I'm just, going to escape from this with, the easiest solution I'll just say try, and accept and I'm just going to, break from this Loop I'll just mix a, print statement over here just to see if, everything is fine, um yeah everything is fine up till over, here, now in this length what I'm going to, return will be the length of self dot X, which will be the length of our data, since the last one is now of no use so, I'll just say self dot X is equals to, self dot X take everything up to, -1 so the last one is of no use, um I'm just going to return over here, now inside this uh read get item I'm I, want to return the Tuple of the, attention mask, and my actual response so I'll just say, self dot input IDs of that idx and self, dot attention mask of that idx basically, so this is our chat class so this is our, chat data class now I'm going to import, this check data class from this so I'll, just says ROM chat data import, chat data and let's uh get rid of this, and each lies are, chat data class I'm going to pass the, path of this chat data object so I'll, just say chat, data.json since it's in the same, directory and other thing it need is the, tokenizer so I'll just pass this, tokenizer over here now some things I, need to uh explain it explain to you, before starting getting inside running, this program it is basically this, tokenizer doesn't know this start off, string basically just bought token and, end of string token and also it doesn't, know the padding token so we need to, tell this tokenizer that this token is, that and this token is that so I need to, do is tokenizer dot add special tokens, and inside this you have to pass it as a, dictionary first will be a pad token so, the pad token is going to be basically, pad, and other thing we need to pass is start, off string and end of string so, beginning of string token, and end of string token and it is start, off string, and, of string, it's all um other than that we need to, tell it this this is a bot token also so, since bot is not HP special token so we, need to say add to buttons and pass it, as a list, spot over here, okay everything looks fine now if we, initiate this we should catch something, so I'll just, try to run this and see, python main.pi, so inside this init, we should see this print statement if, everything is fine we got error it says, the Json object must be string byte a, byte array, so this is not load, yeah we have to use load function, instead of loads, I guess that's the problem let's turn, this one more time yeah we got I love, iPhone I just bought a new iPhone there, is something wrong, actually here will be idx instead of I, let's try this one more time, yeah we got it start of string I love, iPhone I just bought new iPhone and the, bot reply to this is that's good for you, I'm not very into Tech and just end up, string everything is working as expected, um now what we need to do is uh train, our model now in order to train a model, we need to set a parameter model dot, clean we need to get the optimizer so, I'll just say from, from torch, torch Dot optim Port let's just use Adam, optimizer, let's define this Optimum over here this, will be atom and it will going to take, the model parameter so model dot, parameters like that, um other than that yeah one more thing, you have to do this is a pre-trained, model on the pre-trained gpt2 tokenizer, now since we have made changes inside, the tokenizer we have added special, tokens and added this bot token we need, to tell this model that we have made the, changes so in order to tell that what, you can do is model dot resize, token embeddings and you just have to, pass the length of new tokenizer so what, is the new length of tokenizer you can, just pass it like that, uh we have everything we have the, optimizer let's just Define our train, function basically so inside the screen, function what we are going to have is, the, data chat data which is the object of, the class which we have already defined, the model and the optimizer if that's, all for now, now uh let's just Define the epochs so, I'll just print retail for 10 epochs uh, after that, I see for I for I in range, epochs now I need to get the data in the, batch form but this chat data class is, just going to going to return me a, single instance so for that there is a, class inside the torch once again so, just torch dot utils dot data import, data loader, and what you can do is uh come in over, here let me just see that data is equal, to data loader and pass this, chat data and over here you are going to, get option of batch size so for batch, size, we can for now let's say 64 best size, now this chat data we're going to return, as the batch of data instead of, returning just a single sample so I'll, say for x and attention I'll say a in, chat data, so how do I know that it is going to, return to X and A B since uh over here, we have defined get item and this get, item is returning the Tuple and we are, just unpacking our Tuple over here which, is X and E now once we have this we are, going to, use the model and inside this model I'm, going to pass X as an input then, attention mask, and then labels will be X once again I, just come to it just wait a minute, um and it is going to return the loss so, we say loss is equals to that so why did, we uh basically set X as the labels and, set X as the input so if you just get, back to our, gpt2 LM head model over here you are, going to see that they have defined the, labels uh just over here just give me a, second yeah labels over here they are, saying that labels for language modeling, note that labels are shifted inside the, model that is your label uh is going to, be equal to input IDs so basically it is, just shifted one step forward so let's, make sense that we have to pass X as the, labels also and access the input IDs, also now uh we have the optimizer we'll, say optimum.0 upgrade we'll just make, the gradient 0, just like that and after that we are, going to say loss dot back word and then, optim dot step, okay looks fine let's just use tqdm in, order to see, progress, it's like still over here everything, looks fine let's just Define one more, function for making the inference uh, let's just do one thing Define the, inference over here, now in order to save your model your, progress basically let's just do one, thing uh after every Epoch I'm going to, save the model so I'll just say torch, dot save and if model Dot, import, torch model dot State dictionary and the, name will be models, T8 dot PT, okay looks fine to me now for making the, inference basically let's just Define, the function uh infer, so info basically mean making the, predictions so it is going to take the, input, and first we need to uh do this all the, steps which we have already understand, in the beginning of the video first we, need to use the tokenizer so we'll say, tokens is equals to let's just say input, is equal to spokenizer and input before, that we need to preprocess it so you, know we have to follow this same, structure I'll just copy it, paste it over here start of string, input and instead of Bot this time we, are just going to leave it over here, since we are expecting our model to, generate the string after bot now once, we have this over here, um, I guess we can get the output we can see, model dot this time we are going to use, the generate function as we have used in, the beginning of the video to generate, the prompt uh we'll say model dot, generate and it is going to take this, input unpack this the attention mask as, well as the input IDs, now we are going to decode this output, uh we can see output is equals to, tokenizer dot d code, output 0 and return this output, [Music], um, looks good let's just do one thing uh, since my laptop is very small for all, these to train since the data is also so, huge you can already see there is a lot, of data I'm going to use Google collab, for that so let's just go back to over, here I'm just going to create a new, notebook then I'll just get back to you, okay I'm going to connect, and in this runtime I'm going to change, my runtime to GPU for faster training, and inside this file I need to upload, this data Json file so it's in my, desktop over here, and this is the file chat and data.json, and hit ok now let's start importing our, code first of all I'm going to import my, class, so I'll just do this over here, I'm going to run it now let's import our, main dot Pi copy, and import it uh okay if you are getting, error which definitely you are going to, get we need to import the install the, Transformers so we'll say pip is tall, Transformers, uh one more thing I forgot to do is to, uh Mount this model and all the data to, the, Cuda device so I need to Define first of, all the line for defining the device so, I'll say device is supposed to, Cuda, if torch, dot Cuda dot is available, so I have just copied the line so that I, don't have to write it uh just set the, device as Cuda if Coda is available set, the device as MPS if it is basically for, MacBook with M1 chips if mq is available, else set the CPU now I need to say model, is equals to model dot two device, as well as while training, over here I need to set them also to, Cuda so I'll say x dot two, device, similarly, a DOT two device, let's run this one more time, um also, I need to copy the path of this chat, Json and replace this where I was, instantiating my, chat data class, foreign, let us just uh run try to run this and, see if it works or not okay we got error, yeah obviously we have to remove it, let's run this one more time okay it is, downloading the models and libraries so, let's just wait done now we just need to, call this trained function so let's just, say train, pass the model, foreign, [Music], basically it's not like that it is tqdm, Dot tqdm, list object has no attribute to why is, that, we need to convert it how's that, possible since I have set, the tokenizer, yeah we need to set over here return, tensors is equals to, PT, since it is just returning a normal list, so we want it to return the tensor, you need to run it one more time and, hopefully this time it should run, okay there is a lot of data we need to, make some trade-offs over here instead, of using all the data what I am going to, do is, use First, thousand let's just say three thousand, samples, out of memory how's that possible I, think we need to restart our runtime, so I'll say restart runtime okay and now, the GPU is released now try to run it, one more time and hopefully it should, run, foreign, was uh what I did is that the max length, has 40 and set the padding as max length, I guess the problem was that there was a, longest sequence so what tokenizer do it, just take the max length from all the, items you are passing over here and just, make them pad to that length so I just, limited it to length 40 so I guess let's, solve the problem uh now we'll just wait, for it to at least, for at least 60 bucks and we will see, the result is not consuming much memory, over here so I guess we can change the, data set also at least about 5000, samples so we'll have to see that also, I'm I'm just meant to stop it for 60, bucks and try to infer, okay, and see how it works, I need to print this also, the error is basically has no attribute, shape yeah it's the same error inside, this input I'm sending this over here I, need to set return, tensors is equal to PT I'm just going to, cut out this info function from over, here, and Define this info function below it, over here, and just try to run this one more time, okay it should be on the same device, obviously, um, okay, I'll see X is equals to, input input IDs and a is equals to input, attention mask and we'll just say to, device and two, device let's run this one more time, okay hi actually this a and attention, mask is supposed to a, uh he should work out yes it is working, and the port replied with high so I'm, just going to automate it I'll just say, inputs equals to input, and I'll just set input is equals to, this while, and I'm just going to print, info, input, okay I guess that's enough now let's try, to run it and it should be ready now, I'll send hi, and we got, I am not given end of string that's not, good, hello, we got I'm good, how are you, I'm not sure to be, um, what are you doing, I'm not sure to be good so let's just do, one thing it is working uh as we expect, it to let's just do one thing uh, increase the data set a little bit I'm, just going to make it 5000 samples and, other than that uh let's just try to, increase the epochs to at least 12., um also one thing I forgot is to set the, learning rate over here so I'm going to, set LR is equals to, one e let's say minus E how, uh after that uh what I want to do, inside this train I want to infer so, I'll say once the epoch first the epoch, is done I'm just going to infer, hello how are you just to assess the, model so let's just run this now we'll, just have to wait and see how it, performs I'm going to stop it because uh, inside this screen I forgot, to print let's run this one more time, uh what I could have really done is take, out this train function now we are going, to, let's just leave it and paste The Strain, function over here the first Epoch has, passed and we got, the first reply we could ever get let's, just wait for it and see okay three, bucks have passed and we got a reply I'm, a huge gamer not good but at least the, grammar and everything is fine, let's wait for it okay after fourth, hip-hop we got at least a good response, which is high, uh let's just wait I'm getting, a feeling that it was going to perform, better yeah this is really good so I'm, going to stop it over here at this fifth, Epoch and try to make some responses so, over here we got really good response, let's try to run this and see, so if I say hi that's not good I'm here, gamer hello, I'm not sure what you mean I'm very, experienced person, let's say how are you, I like to play games and I like to play, video games that's not good uh, what is your, name, I'm not sure I'm very experienced uh, that's not good let's just keep on, training it, so train it for more epochs okay let's, try to stop this right over here and try, to make some predictions we got high how, are you, uh we got how old are you, I am fine how about you, I'm fine fine how are you doing, uh do you love books, I love it I have a new library at home, okay that's good which, books you love, I read in English Okay so you can see, that it is producing pretty good, responses uh considering the amount of, data we trained on and the amount of uh, epochs uh there is a lot of scope uh in, Improvement of this particular chatbot, so what I will basically do write all, this code in down description there will, be a GitHub link uh feel free to, contribute to it and make the changes to, the code and we can just make this a, better chatbot let's just proceed into, this uh and try to see what better do we, get let's say, do you like, coding, I like code and I love it, reach, coding language, you like most, graduated that's that that doesn't make, sense, um I say I want to marry you, okay he sent key just key, um I'll say What is your, Hobbies, I like to read watch movies okay, I hate, you, what do we get, nothing, um, I need some money, do you have it, uh can you, give me some money, I have no idea I'm more of a cat person, um what can we ask it how what is your, name, I'm not sure I'm very experienced person, okay what, do you, do for, living, I like to read books and watch movies, okay I'm going to just stop this video, over here um in case of replies I will, just going to go on it will never end uh, basically all the code will be in down, description if you want to contribute to, this code I am open to it, um and if you want to run this code, again this is in the description that's, open source, um I'll just stop this video right over, here if you have any queries you can ask, them in the comment section uh that's, all for this video uh it's already been, how long, one are actually there will be a lot of, trimming since you see the training part, and a lot of stuff so I just add this, video right over here till then goodbye, and keep coding and we'll catch you, later",
  "zh text": null
}