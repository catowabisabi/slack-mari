{
  "title": "The best LLMs (3B to 13B models) - Conversational AI",
  "summary": "詳細信息摘要：Chatbot Arena是一個應用程序，允許將兩種語言模型（LMS）進行測試。該測試旨在根據理論物理和統計數據分析提示。經過一周的測試後，比較結果並應用了評級系統。LM13B是130億個參數LM，最高的是LM12P，即120億個參數LM。令人驚訝的是，Plan T5是Google T5的微調版本，只有30億個參數，是第三好的表演者。開源非商業LM的性能也很好，有130億個參數。結果表明，即使使用較小的模型，也可以通過微調實現良好的結果。可以提供用於培訓LM和計劃T5的代碼和視頻。\n\n子彈點摘要：\n•聊天機器人競技場是一個測試語言模型的應用程序\n•經過一周的測試，LM13B（130億參數LM）是獲勝者\n•LM12P（120億參數LM）和計劃T5（30億參數LM）緊隨其後\n•開源非商業LM也表現良好，有130億個參數\n•結果表明，即使使用較小的模型，也可以通過微調實現良好的結果\n•可用於培訓LM和計劃T5的代碼和視頻",
  "dialogue": "hello community so what is the best LOL, I'm around and there's a beautiful, application I would like to show you, this is called chatbot Arena here two, llms fight against each other so let's, have a look we have here my prompt, explained in pure scientific terms the, fundamental ideas behind Quantum field, Theory and theoretical physics and now, two systems try to analyze it Model A, and model B, and I at first do not know what is model, a mod what is model B but I have to vote, is a better or B better or is there a, tie and are both bad or which one is, more advanced so it's a blind test that, tells you exactly what it is all about, so you see here for example between A, and B at least in the length of the, answer there's a clear difference so let, me give me a minute and I have a look at, the content here, so we are back and I would definitely, say based on the result of my experience, B is better, so you see here Model A was alpaca 13B, and model B was yeah of course gpt's, chat GPT so GPT 3.5 trova so you see and, you get a lot of results in this way and, last week, if you wanna now know how you compare, if 5 000 people did this you have now, here a simple notebook it's a call up, notebook I give you the link you can, download it so they have now a specific, rating system that they apply and they, say hey let's have a look how the two, system performed and of course it is, about theoretical physics it is about, statistic and you see here you have your, raw data you have Model A, this was here now parka 13B and this was, a dolly 12p and then you see who was the, winner, the timestamp and the language it was, performed and you see you get a lot of, data and if you have in one week five, thousand uh comparison so you have here, about 10 000 rows beautiful, then you do a little bit of Statistics, you do a little bit of cleanup you do a, little bit of mathematics and you say, yep I want to have a look at this in, detail yes you can you can of course you, ask the peer-wise proportion if you want, to know more about the ELO rating system, Wikipedia has a nice article about it so, if you're interested no problem at all, and then you have a preliminary rating, and then you have the computed ratings, and here we are and if you want to see, this this is now the result here, of last week's model but of course you, can go here and if you go here the, leaderboard here we have now our winners, and here we have here the 13 billion, 13 billion and a 12 billion llm places, one two and three, now just want to tell you to be fair the, whole thing is done by LM sis and now, the first place goes to lmcis, uh okay this could be a coincidence but, they are very transparent they give you, here all their computation we have to, battle here in the chatbot Arena and, they really want to find out on the, viewer on the person that is using an, llm you just saw it, how can we judge it and it's my personal, judgment but I think it is a really, interesting result and I want to show, you something particular here look if, you go now with, here the open Assistant with putia or we, go with koala okay this is yeah marginal, I would say here in the ratings but, there's one Naya then you have alpaca of, course and then you have two very, specific look we have here Dolly with 12, billion and here we have from Mita Lama, with 13 billion so you see based just on, what users wrote in a blind test llama, is here with 13 billion parameters, so this one that is restricted that is, non-commercial you're not allowed you do, not get a license, but you see there are so many other, beautiful free opinions but there's two, nice things well one nice thing look you, have the smallest model is just three, billion here, and you know what is here with three, billion the winner plan T5, so highly interesting, that if you have now plan T5 which is a, fine tune T5 by Google and then you have, a chat assistant fine tune on this flat, T5 by a specific company since they have, this chat data with the fastjet T5 3, billion parameter model you get really, good results because look this is 950, and here the place number three is it's, 1065. so the difference for a three, billion parameter to a 12 billion, parameter four times bigger but it is, relatively comparable so if you have you, if you want to do this on your GPU at, home and maybe you do not have a 12, billion parameter infrastructure at home, a computer infrastructure the best 3, billion parameter model on this, Battleground here is a flan T5 that has, been now for a chat application for a, chat Downstream task again fine-tuned on, a chat assist fine tuning so you see, according to this data last week this, best 3 billion parameter model plan T5 6, billion is here, by this University and then you have, more or less koala or PTO if you want to, know more about this where's my koala, here's my dolly if you're interested in, here's my koala here is my alpaca code I, have three videos on the detailed coding, on gpt4, here is my Stanford alpaca and if you, want to train alpaca, on the T5 or the flan T5 model those, here are my two videos for you if you're, interested and a little bit more the, code and the details so it gives you a, very nice overview please participate, here in the chatbot Arena have a look, for yourself, insert here your particular text your, particular topic your particular, language maybe even if you're a, non-english speaker have a look what, model is best for you it's a blind test, but if you do this four or five times, you immediately see what is the best, available model for you and it is free, and you help the community to get, evaluation results based on different, application this was it for today I hope, you learned a little bit and I'll see, you in my next video",
  "zh text": null
}