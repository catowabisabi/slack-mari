{
  "title": "Exploring The Power of GPT4All model in Langchain: Testing with Langchain Tools, Agents and Chains",
  "summary": "詳細信息摘要：此演示文稿是關於使用工具，代理和鏈條在長鏈測試中探索所有人的力量。主要目的是演示如何將GPT模型與啟動中的類構造相連。使用的模型是盧卡斯先生倉庫中所有Lora模型的量化GPT，該模型託管在擁抱的臉上。主要的挑戰是將提供給模型的提示和數據歸功於該提示和數據。該視頻還將共享筆記本電腦，Python腳本和Google Server API。該視頻還將解釋Langchain庫和大型語言模型。最後，該視頻將演示如何在啟動下安裝和使用Llama CPP Python庫。\n\n子彈點摘要：\n•探索GPT對所有人和長鏈測試的力量\n•將GPT模型與類構造接口\n•對盧卡斯先生倉庫的所有Lora模型進行了量化GPT\n•主要的挑戰是將提示和數據施加\n•共享筆記本，Python腳本和Google Server API\n•解釋Langchain庫和大語言模型\n•演示如何安裝和使用Llama CPP Python庫",
  "dialogue": "welcome to inside Builder Channel large, language model automators python experts, and my dear friends, exploring the power of GPT for all, inside longchain testing with tools, agents and chains, the intention of this presentation is, going to be, working with GPT for all in your local, environment that is the primary you know, purpose of this, even though you would have already seen, a lot of videos where they show how to, run this in local environment this video, will go one step above and it will start, working with various ways of interfacing, the GPT model with the, class constructs in launching that will, be the primary objective of this, presentation so before I go really into, the presentation I just gave an overview, let us go back to the browser the GPT, for all, was introduced was has been you know, released by nomik Ai and you must have, heard about it a lot I am not going to, go in detail about this, the point here is that we are going to, primarily concentrate on how to get this, work in our environment, before we start I really thank the nomik, team Lucas reussell who uploaded the, normic contest model in hugging face, we'll be using his the uploaded model, and Thomas Anthony who helped in, creating llama CPP python Library which, will be used by land chain in order to, interface the model in interface the, model that is GPT for for all model with, launching so all these people have done, a great job so that today we can, actually start working with python and, launching so a lot of work has gone in, this this is very important because at, the end of the day the step that they, are, that these people have done nomic, crucial Mr crucial and Mr Thomas has, actually you know let us let us to use, it use the model more easily in our, environment, we will if you are thinking okay white, test and what are the tests that is, going to be done most important point is, that large language model as I was, explaining is kind of a controller or, it's more of a more of a backbone when, it comes to working with the various, interfaces like your data stores your, files your services future it is going, to be like that having a large language, model that is present locally and you, can use it at your will is going to, change how we interact with uh interact, with the world in in near future so I, hope that you guys will you know really, understand what is going on here and, also you know implement it in your own, environment the in the way this, particular video is made is a particular, test and the videos made is that I will, be introducing the test that is done and, then I'll be also sharing as usual the, notebooks as well as this time that will, be a script also, in all the previous videos I only shared, the collab notebooks this time I had to, move these move to a script move the, commands to a script the python script, which can be run in your local, environment and you can test it by, yourself, the point of creating this is that then, by running it in your local environment, only you can understand what is actually, going on without that it will be, extremely tough for you to really to, judge that okay whether how to use this, technology so that is the main intention, of this and I hope that you like these, videos and do leave a like and share it, with others very important guys please, share this technology with others and, subscribe to my channel so that further, updates online chain and the Big Data, related Concepts will be shared here, with that said let us go to the tests, initially I'll be working with with the, simple large llm concept so I will not, have any kind of uh any kind of change, or anything it will be a simple Lang, chain based llm, I did not get any output when I was, testing it in the collab notebook when I, created my llm chain class object then I, got an output in case of pandas data, frame agent it errored out and in case, of request chain also it errored out, this is all in collab notebook okay I am, I'm not talking about in script in, script I have still kept this but I have, I will be showing it to you I have, commented it out so but I have anyway, still recorded it there because in the, future when the things change we will, update it right and finally llm along, with other tools and initialized agents, so when I started working with the tools, like Google server API and initialized, it as an agent then it was able to, actually get the output and it was uh I, was actually surprised by that, so uh you will be seeing this in action, in a moment, the major challenge what I uh what I, understand from this various test is, that how we tokenize the prompts and the, data that is given to it so that is, where these two uh these two tests, failed so I have actually given the, failed tests also here because see, when you are only going to share, everything that is Success you might, actually think okay this is easy but, believe me guys it has to be it has to a, lot of research goes on into this and I, I, personally want you guys also to explore, more because uh once we start exploring, once you guys start exploring together, then we can learn a lot so that is the, main intention of you know sharing what, is exactly going on also so that it will, be much more useful for you and, uh the whole community, as I was telling all these people have, done a great job and they have moved the, community has a whole a step forward I I, would say a hundred step forward but, still, so with that said let us go to the, collab notebook and start working on, that so going here if you guys by any, chance are coming to this video directly, and you are not aware of language line, chain or large language models take a, look at this playlist where I explain, everything from the beginning, for not only the line chain library but, also on the large language models you, can get a good idea about that, and the repo where the code the Jupiter, notebook as well as the python code, stored will be shared to you in the, video description that is uh in the, below in the video YouTube video, description take a look at that you can, get the code from there and this is the, report that you will be working on and, finally coming to the collab notebook, this is the collab notebook you have to, just use file and say upload notebook, and you have to give the GitHub repo, link and it will open this particular, notebook so, note this point when you are going to, your regular environment you need to, install all this in your regular, environment okay ensure that you all, these are important libraries so ensure, that you install it before you work on, the regular environment coming to the, first and foremost step we get the, quantized GPT for all Lora model from Mr, Lucas's repo it is again face report the, model has been uploaded we will be, pulling it and once you pull it inside, the Google collab notebook it will it, will get them get populated in the, content directory so that will be the, root directory once you do this once you, don't need to do it again so this is a, 4.2 GB, um, model so ensure that you have sufficient, bandwidth or else you will actually you, know end up in trouble so you will not, get the model it will so you understand, what I'm trying to say, the we are we are going to start working, with a llama CPP class inside, linechain.lm so when you are going to, install it in if you already installed, line chain better do a pip install, upgrade launching so here when I am, doing here you see that I am doing pip, install launching but when you are doing, user upgrade here so use the upgrade, option and then do the launching what, happens is it will pull the latest, classes or latest code that has been, written by the launching developers and, it will put it in your own in your own, environment or else this particular, class will be erroring out it will say, that okay Lang chain does not have this, class so ensure that you you properly, install it, and I have just run it already because I, do not want to want you guys to waste it, so waste your time so I've already run, it and I am using very simple you know, prompt templates and this is the, important point so I am initiating the, model so all you need to do is just pass, this model path into Lama dot llama CPP, with capital c and the model gets, initialized, behind this uh behind the simple class, initialization lot of code actually goes, on which is not shown to us so it has, been completely abstracted, line chain guys have done a great job I, want to leave a shout out here for them, and uh you know it's one of the it looks, very simple right it looks you know, extremely simple that all you do is you, know create a class but in fact it's not, that simple if you take a look at the, various libraries involved and various, code unit execute to get this model in, it's not that easy because I was uh I, was planning to create a much longer, notebook because I had to go multiple, steps to get this model loaded into line, chain object that is to create a large, language model that can be, operated by launching, environment but thanks to llama CPP we, don't need to do it so all I need to do, is just run this single sentence and, after that when I tried okay after the, after that when I asked the question uh, which team NFL team won the Super Bowl, and the year Justin Bieber was born and, I gave the question it actually did not, give any output so it took a lot of time, and also ensure that it will take a lot, of time guys the ram also it will take, it will take around four to five GB of, RAM so I'm sure that you have a good Ram, in your machine also because you are, going to run all these things as a, script I'll be showing you the script, also in a moment inside the inside the, command prompt, so I create a chain here llm chain that, is again a large language sorry that's a, line chain class again and when I ask, this question so the same question I, send it through this and we we get the, answer, okay the you see the answer here so you, the answer is right actually I checked, it out also I think the answer is right, but whether the answer is right or wrong, that is the secondary thing the point, here is that it is able to properly go, through the question it is also you know, rephrasing the question and responding, to us back in the llm chain so this is, one of the good things that I actually, liked about and I wanted to share with, you guys also, and then starts the challenge okay so I, got this chain right so I got greedy so, I wanted to get the pandas data frame, immediately red and I want to do lots of, analysis and I wanted to work with, request chain also but both of these, things errored out, okay the what I find from so I'll be, executing this so I I have not executed, that earlier I can execute it right now, so what happened was that it enters into, the chain and then it actually says that, failed to tokenize so what I understood, is that the data that I'm pushing into, the environment is actually huge and, when I am you know initiating this large, language model right I need to I think I, need to also understand what goes on in, internally how much is the tokens Etc I, need to modify that okay as of now that, particular study I have not done so that, could be the you know one of my one of, the mistakes that I have made but still, this is what uh is the result so uh we, see that and then I wanted to create, request chain and in case of request, chain also I started facing the same, problem so when I was sending the, request in what it was happening is, again so the request was going out so I, asked what are the three biggest states, in India and its population so I'm, asking for a Google search using a, requestion I am not using any of the, apis here it's a request chain that is, going to work and I am writing the net I, am executing this and I get the similar, kind of an error because I I think that, it is because of the token sizes or the, contacts that we are providing so it is, still getting the data you see the data, is coming out, probably have allowed to zoom in a bit, so I hope that you guys are uh sorry I, completely forgot about zooming in but I, hope it is still visible, so the point I was trying to make is, that uh we can see that it is returning, the data however uh because the llm is, unable to process it it is erroring out, okay so we have to still work on this, but yeah apart from all this quirks, the final point I was doing was I used, the load tools and use the, initialization agent okay just a minute, I will be uploading I am in updating the, serp API key here and I will be getting, back to you, so I have already loaded this and now I, am going to load the server Google, server so this is actually serper API, key you have to just put your API key, here and I'm initializing the agent this, is the regular process that we follow, and then I ask okay what is the weather, in Delhi and you see it actually gives, the replay back, the point that I wanted to make is first, and foremost ensure that you give, sufficient time don't be in a hurry you, have to test it out step by step okay, and also ensure that your system is up, to date not from the perspective of your, uh what is it software handle you need, to be you need to take care of the, Python packages are up to date because, most of the time in case of collab, notebook a lot of packages are already, installed in the collab notebook and, when you try it in your local, environment when I'll be showing the, script in a moment just uh just let me, show this group so this is the script uh, that will be it's already shared with, you guys before that let us see what is, happening here the agent executor is, still running you saw that it's already, almost two minutes it is still running, but anyway let us go and start, explaining you the script script is, nothing different guys I have just taken, you see even the script is directly, taken from the pull up notebook only I, have not changed anything the point here, is that in my script I have commented, out the download because when I am, running I've already run it once so I, don't need to get the model again so I, have commented it out when you start, uncommented and then start working okay, and I'm I am going through the same, process that I show in the collab, notebook only thing is I have added, additional print statements so that you, will understand what is going on so like, the print statements that you see here I, have did it and this is the first llm, where it is yeah, just a minute this is the template that, is getting created and reply, this is the first reply so you see this, I have actually commented it out because, it's not giving me any value so when you, run your script you can uncomment it and, do the script run and see what happens, okay and in this case replay 2 is using, the llm chain it gives the reply you can, see that I will be showing it in couple, of minutes and then I continue with this, again here I have passed the triac, except block because the reason is that, this particular the agent when I try to, run it using the uh using the data that, is provided so this data the space, shortened CSV also is available inside, the repo only so you can find it out, inside the repo I think it is inside the, one of the project folders I will share, the link also so that you can you guys, can get it or you can put your own csvs, it doesn't matter there you can you can, just edit it and you know update your, own CSV file that is available with you, and try it out but the point the, challenge is that you understood you, understood right it will error because, it is unable to tokenize and then I use, the request change and that also again, passed it so here I initiate the net, chain and then I try accept it using the, reply process I why I'm using try accept, because I am running a complete script, so if any of the replies fail or if any, of the prints fail then I will I will, just accept it and go to the next step, or else my script will stop so that is, why I used it and also this script will, require your server API key to be, provided as provided along with the, along with the command when you are, executing python the script name python, Explorer exploring underscore GPT for, all.py after that you need to give the, uh the key the server API key because in, that way I can share the when I do it, like this I can share the code with you, guys without you know thinking twice and, then I am loading the tools I am, initializing it and this replay I am, also going to share it with you I think, it is done here and we see the result, here and you can check it out that it is, overcast by 41 degree celsius at uh in, Delhi right now the point I wanted to, make it here make here is that the the, GPT for all actually you know it works, with 4GB of RAM and it is it is easily, loadable so we saw this script also now, what I'm going to do is I will connect, to my machine and I will show it you how, to execute this okay just give me a, moment, I hope you guys are able to see the, prompt here I am going I have already, get cloned the entire Library entire uh, repo here and I am entering into the, folder where my code is available the, code is available inside langchang, in just a minute it's in projects Lang, chain x uh I think it is exploring GPT, for all the code is inside here so if, you do an LS now you'll see that I, already have the model here you see this, so you should keep the model in this, place only ggt gggat hyphen model dot, bin you once you execute it once you, will get it get the model directly also, in this location only and here also you, see the space underscore shorten CSV, that I shared it with you in a moment, upward is already available there once, you pull the repo you will get it and, the the document exploring underscore, GPT for all.pi this is the uh this is, the, python script that will we will be, executing so I will be just doing a cap, command and I will be showing it to you, guys whatever I was I showed it to you, in the in the rep in the GitHub repo the, same thing I have just pulled it here, okay nothing different what I'm going to, do right now is uh I'll not be able to, show you my server API key right so what, I'm going to do is I'm going to execute, this and I will get back to you, foreign, started loading and all these things, happened inside the collab notebook also, but it was not visible to us because it, was in the inside this cell we we, couldn't actually see that so now you, are seeing it in a step-by-step process, and give it time guys because this see, my the laptop the system that I'm, connecting with is in the cloud instance, and I have given a four or eight GB of, RAM I suppose I don't exactly remember, that it's in between that and uh it is, it takes Consular amount of time because, the entire process goes through various, kinds of you know Loops when it comes to, large language models and getting, coherent sentences out it is not just, neural networks actually there is, mathematics also involved when the data, is given by the large language model or, the neural network the words are again, rechecked by a local algorithm whether, the particular word frequency is you, know sufficiently matching with the, regular coherent sentence so that is a, kind of a you know process that goes, through in in the back end if you there, is a separate uh you saw that the first, replay we got it you see the data here, reply from llm chain and uh the rest of, the things I have actually skipped so, agent setting has been done all these, things I have skipped it in this place, it is not running right now it is, directly jumping to the last step, why I skipped it because I already, showed you guys that it is erroring out, I did not want to you know spend again, time because each of this time right, each of this step it will try to get the, data for you and each of these step it, will error out instead of seeing the, errors here in the script I already you, know showed it in the collab notebook so, you guys can still let me let it run in, the meantime let us go to the browser, and in the browser yeah you can you can, uncomment it and run it whenever you, uncomment it understand you have to, uncomment uncommented remove the pass, remove the pass from here and then run, it so run it one by one I have given you, all the things you don't need to run, everything by a single go you will get, frustrated that it takes a lot of time, why to do that so you you go step by, step and understand okay what is going, on and uh you you you will understand uh, very very clearly that how this is, working let us go back to the terminal, once, okay still the executor is not completed, it takes almost two to two point five uh, minutes so it's a regular thing now let, us go back to the PDF now, because I wanted to uh you know think, for you guys also and I wanted you guys, also to think right now since you have, the GPD model write at your you know, command prompt how are you going to use, it and what purposes you will be think, what purposes you can think of first and, foremost what I thought of is you know, to have a personal assistant just by, using a python script the script is, already available you saw that right all, you need to do is you know write a while, loop so that it it keeps on running so, you do you have to just ask it something, you have to wait a bit probably it's not, as fast as uh whatever you are seeing, from GPT 4 or gpt5 or whatever model, comes out however all those models have, one big disadvantage that is it is, outside your system this particular, model is inside your system right at, your control it is connected with line, chain you can do a lot of stuff with it, using python you can log whatever you, are asking for you can try to work with, various kinds of interfaces various, kinds of files you can play with the, token models understand the how the, tokening is working so as I always you, know say at the end of my videos, practice guys and now this practice is, going to be pretty interesting it's not, going to be boring if you have done all, the earlier practices now it will become, interesting the the point here is that, as you practice all these steps that I, am telling in the present in my earlier, presentations will be very useful in, this in this particular time of, discussion let us see whether it is done, let me check it yeah I think in in my, case it has done that I'm I'm going to, show it to you so you see this the, output has been populated here and you, see what is the actual number of tokens, the number of runs it has gone through, you can get a lot of information and it, says okay it is saying daily is a 20, degree celsius I think it is getting a, older data, okay that is all fine so it is giving, wrong information you can run it again, and see the point I am trying to make it, here is that it is actually pulling the, data and I am thinking it is getting the, data from a different search result so, that is why the issue is coming you can, I actually try to experiment with that, you can also experiment with the script, also let us go back to the presentation, and uh so that is the point I wanted to, share with you guys so I hope that you, guys will be able to use this notebook, Jupiter notebook as well as the script, very helpfully and usefully uh the here, the link is uh you know wrong but I will, be sharing you the correct link in the, in the description so and also again the, code will download 4.5 GB of model to, your local environment keep that in mind, when you're executing the code just, blindly if you execute and suddenly you, see okay your space is missing or if, your bandwidth is gone then it's because, of the model has got downloaded so keep, that in mind and uh yeah thanks for, watching again uh do do practice that is, very important and share this, information with others and also, subscribe to my channel so further, updates regarding blank chain as well as, various other, related libraries to large language, models to Python and to Big Data will be, shared with you guys so in the next, video with forwards I take the leave, practice practice practice practice",
  "zh text": null
}